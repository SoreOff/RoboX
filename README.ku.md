# RoboX - Wayback Robots URL Extractor

ئەم سکریپتە مێژووی `robots.txt` بۆ دۆمەینێکی دیاریکراو لە Wayback Machine وەردەگرێت، هەموو وەشاندنە ئەرشیفکراوەکان پرۆسە دەکات، و URL-ەکان کە لە ناویدا دەدۆزرێنەوە دەستنیشان دەکات و پاشەکەوتیان دەکات.

## تایبەتمەندییەکان ✨

- هەموو وەشاندنە مێژووییەکانی `robots.txt` بۆ دۆمەینێک لە ئەرشیفی ئینتەرنێت وەردەگرێت
- URL-ەکانی `Allow:`، `Disallow:`، و `Sitemap:` دەردەهێنێت
- لینکە دەرهێنراوەکان بە فۆرماتی `txt` و `json` پاشەکەوت دەکات
- `asyncio` و `aiohttp` بەکاردەهێنێت بۆ پرۆسەکردنێکی خێراتر
- لە دروستکردنی فایلە دووبارەکان دەپارێزێت و لە حاڵەتی هەڵەدا بەردەوام دەبێت لە بەکارهێنانی فایلە ئامادەکە


## دامەزراندن 📦
```bash
pip install -r requirements.txt
```

### پێداویستییەکان

دڵنیابە کە ئەمانەت دامەزراندووە:

- ‍‍`Python 3.7+`
- `aiohttp`
- `requests`

## بەکارهێنان 🚀
```bash
python3 robox.py <domain> [batch_size]
```

### نموونە
```bash
python3 robox.py example.com
python3 robox.py example.com 100
```

### چییە؟ `batch_size` ⚙️

پارامیتەری `batch_size` دیاری دەکات کە چەند وەشاندنی `robots.txt` لە یەک کاتدا پرۆسە بکرێن. بەهایەکی بەرزتر پرۆسەکردن خێراتر دەکات بەڵام دەکرێت بارێکی زیاتر بکاتە سەر سێرڤەرەکە. بەهای بنەڕەتی ئەوە `50` یە.


## دەرچوون 📂

- `<دۆمەین>_urls_<timestamp>.txt` → لیستێک لە URL-ە دەرهێنراوەکان لەخۆدەگرێت
- `<دۆمەین>_urls_<timestamp>.json` → زانیارییەکی زیاتر لەخۆدەگرێت وەک کاتی جێبەجێکردن، کۆی وەشاندنە پرۆسەکراوەکان، و کۆی URL-ە دۆزراوەکان



## مۆڵەت ⚖️

ئەم پرۆژەیە بە مۆڵەتی MIT مۆڵەتپێدراوە.
